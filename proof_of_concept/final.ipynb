{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLOCK 1: DIV PROYECT:  <b><i>Eventful<i></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalation and credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q spotipy\n",
    "%pip install -q spacy\n",
    "%pip install -q ratelimit\n",
    "%pip install -q bs4\n",
    "%pip install -q langdetect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credentials and data authorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Credentials</b>: we load the credentials needed to use the <i>APIs</i> or <i>Web scrapers</i>. These are stored in a safe location in a separated file, for security purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necesary imports throughout the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import requests\n",
    "import urllib.request\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import spacy\n",
    "import spotipy\n",
    "from spotipy import oauth2\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from ratelimit import limits, sleep_and_retry\n",
    "from IPython.display import clear_output\n",
    "from credentials import * # These are the credentials\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_json = {}\n",
    "try:\n",
    "    with open('data.json', 'r') as file:\n",
    "        final_json = json.load(file)\n",
    "except json.JSONDecodeError as e:\n",
    "    raise Exception(f'Error: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the artists\n",
    "TOP_ARTISTS = list(final_json.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to limit calls per second\n",
    "\n",
    "This function aims to avoid the issues that arise when an API is called many times per second.\n",
    "It is setup to 1 call per second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 call per second\n",
    "CALLS = 1\n",
    "RATE_LIMIT = 1\n",
    "\n",
    "@sleep_and_retry\n",
    "@limits(calls=CALLS, period=RATE_LIMIT)\n",
    "def check_limit():\n",
    "    # Empty function to limit calls to APIs\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ticketmaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ticketmaster:</b> we take a list of the currently 50 most listened artists, and we check which of those have upcoming concerts. Then, we gather those concerts and their important data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "artists = {}\n",
    "photos = {}\n",
    "\n",
    "# This function will be used later. It calls the Seatgeek API to add alternative prices to an event, and enrich our original data\n",
    "# To find the event, we make a call using the artist name and the date\n",
    "def find_alternative_price(artist, date, time):\n",
    "    # We need to transform data in order to have the Seatgeek API understand it\n",
    "    search_artist = artist.replace(\" \", \"-\")\n",
    "    search_date = date + \"T\" + time\n",
    "    # We need to have the search terms be in ASCII code for the Seatgeek API to work\n",
    "    if len(search_artist) != len(search_artist.encode()):\n",
    "        return \"Inexistent\"\n",
    "\n",
    "    search = f\"https://api.seatgeek.com/2/events?performers.slug={search_artist}&datetime_local={search_date}&client_id={SEATGEEK_API_CLIENT_ID}\"\n",
    "    check_limit()\n",
    "    with urllib.request.urlopen(search) as url:  \n",
    "        data = json.loads(url.read().decode())\n",
    "\n",
    "    # We make sure that there is only one concert as result (more would mean we cannot find the exact concert, less would mean that the concert is not on Seatgeek)\n",
    "    # Then, we take the lowest price for that event and return it\n",
    "    if data[\"meta\"][\"total\"] == 1:\n",
    "        return data[\"events\"][0][\"stats\"][\"lowest_price\"]\n",
    "\n",
    "    # If something fails along the way, we return that there is no alternative price\n",
    "    return \"Inexistent\"\n",
    "\n",
    "# We will find the unique Ticketmaster API identifier of each artist using their name. We will store it in a dictionary \n",
    "# We need to do this in order to find only the concerts of the original artist (not tribute concerts for example)\n",
    "for keyword in TOP_ARTISTS:\n",
    "    # regx = re.compile('\\W')\n",
    "    # if_space = regx.findall(keyword)\n",
    "    keyword = keyword.replace(\" \", \"\")\n",
    "    # We make a call to the Tickermaster API and store the information, downloaded in json format, in a dictionary\n",
    "    search = f\"https://app.ticketmaster.com/discovery/v2/attractions.json?&keyword={keyword}&apikey={TICKETMASTER_API_KEY}\"\n",
    "    check_limit() \n",
    "    with urllib.request.urlopen(search) as url:  \n",
    "        data = json.loads(url.read().decode())\n",
    "\n",
    "    # We access the section of the dictionary in which the id's of artists are stored, and retrieve it\n",
    "    attractions = data[\"_embedded\"][\"attractions\"]\n",
    "    for attraction in attractions:\n",
    "        if attraction[\"name\"].replace(\" \", \"\") == keyword:\n",
    "            artists[attraction[\"name\"]] = attraction[\"id\"]\n",
    "            # Extra information, used only for Part 2\n",
    "            photos[attraction[\"name\"]] = []\n",
    "            images = attraction[\"images\"]\n",
    "            for image in images:\n",
    "                photos[attraction[\"name\"]].append(image[\"url\"])\n",
    "\n",
    "# Extra information, used only for Part 2\n",
    "with open('photos.json', 'w') as file:\n",
    "        json.dump(photos, file, indent=4)\n",
    "                \n",
    "\n",
    "# We will find concert information for all of the concerts of each artist (using their id), and store it in a dictionary\n",
    "information = {}\n",
    "for artist in artists:\n",
    "    # We make a call to the Tickemaster API.\n",
    "    search = f\"https://app.ticketmaster.com/discovery/v2/events.json?&attractionId={artists[artist]}&apikey={TICKETMASTER_API_KEY}\"    \n",
    "    check_limit()\n",
    "    with urllib.request.urlopen(search) as url:  \n",
    "        data = json.loads(url.read().decode())\n",
    "    \n",
    "    # We discard artists with no upcoming concerts\n",
    "    if data[\"page\"][\"totalElements\"] == 0:\n",
    "        continue\n",
    "\n",
    "    # We create an entry in the dictionary for each artist. It will have a list of concerts\n",
    "    information[artist] = []\n",
    "    events = data[\"_embedded\"][\"events\"]\n",
    "    for event in events:\n",
    "        try:\n",
    "            # Some fields are absolutely necessary for the functionality of the app: name, url, date and time, price, and venue\n",
    "            # Thus, if they are not available in the original data source we will ignore that concert\n",
    "            name = event[\"name\"]\n",
    "            url = event[\"url\"]\n",
    "\n",
    "            date = event[\"dates\"][\"start\"][\"localDate\"]\n",
    "            time = event[\"dates\"][\"start\"][\"localTime\"]\n",
    "            timezone = event[\"dates\"][\"timezone\"]\n",
    "\n",
    "            # We take the lowest price (remember that we want to find the cheapest, most convenient event).\n",
    "            # We will ignore concerts with a price of 0â‚¬ (since in this context it usually indicates that prices have not been oficially released yet)\n",
    "            prices = event[\"priceRanges\"]\n",
    "            minPrice = min(prices, key=lambda x:x['min'])\n",
    "            cheapestPrice = minPrice[\"min\"]\n",
    "            currency = minPrice[\"currency\"]\n",
    "            if cheapestPrice == 0: \n",
    "                raise KeyError('nullPrice')\n",
    "            \n",
    "            venue = event[\"_embedded\"][\"venues\"][0]\n",
    "            venueName = venue[\"name\"]\n",
    "\n",
    "            # Using the information we have from Ticketmaster, we look for the price of the same concert on Seatgeek\n",
    "            alternativeCheapestPrice = find_alternative_price(artist, date, time)\n",
    "\n",
    "            # We have stored the information in variables while checking it is valid. \n",
    "            # When the checks have finished, we will store the information in a dictionary for each concert.\n",
    "            information[artist].append({})\n",
    "            information[artist][-1][\"Concert Name\"] = name\n",
    "            information[artist][-1][\"Concert URL\"] = url\n",
    "            information[artist][-1][\"Date\"] = date\n",
    "            information[artist][-1][\"Time\"] = time\n",
    "            information[artist][-1][\"Timezone\"] = timezone\n",
    "            information[artist][-1][\"Ticketmaster Cheapest Price\"] = cheapestPrice\n",
    "            information[artist][-1][\"Seatgeek Cheapest Price\"] = alternativeCheapestPrice\n",
    "            information[artist][-1][\"Currency\"] = currency\n",
    "            information[artist][-1][\"Venue\"] = venueName\n",
    "\n",
    "            # Some more information is optional: city, country, classifications (concert genre), parking information, accesibility information\n",
    "            # We will check if it is available, else we will simply indicate that it is not (but still keep the concert in our list)\n",
    "            if \"city\" in venue: \n",
    "                information[artist][-1][\"City\"] = venue[\"city\"][\"name\"]\n",
    "            else: \n",
    "                information[artist][-1][\"City\"] = \"Not Specified\"\n",
    "\n",
    "            if \"country\" in venue: \n",
    "                information[artist][-1][\"Country\"] = venue[\"country\"][\"name\"]\n",
    "            else:\n",
    "                information[artist][-1][\"Country\"] = \"Not Specified\"\n",
    "\n",
    "            if \"classifications\" in event and len(event[\"classifications\"]) > 0 and \"genre\" in event[\"classifications\"][0]: \n",
    "                information[artist][-1][\"Main Genre\"] = event[\"classifications\"][0][\"genre\"][\"name\"]\n",
    "            else: \n",
    "                information[artist][-1][\"Main Genre\"] = \"Not Specified\"\n",
    "            if \"products\" in event: \n",
    "                products = event[\"products\"]\n",
    "                for product in products:\n",
    "                    if product == \"Parking\": \n",
    "                        information[artist][-1][\"Parking Service\"] = \"Yes\"\n",
    "                        break\n",
    "                else: \n",
    "                    information[artist][-1][\"Parking Service\"] = \"No\"\n",
    "            if \"accessibility\" in event and \"info\" in event[\"accessibility\"]:\n",
    "                information[artist][-1][\"Accessibility Services\"] = \"Yes\"\n",
    "            else:\n",
    "                information[artist][-1][\"Accessibility Services\"] = \"No\"    \n",
    "\n",
    "            # Extra Information, used only for part 2\n",
    "            latitude = venue[\"location\"][\"latitude\"]\n",
    "            longitude = venue[\"location\"][\"longitude\"]\n",
    "\n",
    "            information[artist][-1][\"Latitude\"] = latitude\n",
    "            information[artist][-1][\"Longitude\"] = longitude\n",
    "            \n",
    "        except KeyError as e:\n",
    "            pass\n",
    "\n",
    "    else:\n",
    "        # We delete information about an artist if no concerts have been found (or only concerts with incomplete information)\n",
    "        if information[artist] == []:\n",
    "            del information[artist]\n",
    "\n",
    "# We store the information in the final json file\n",
    "for artist in final_json:\n",
    "    if 'Concerts' not in final_json[artist]:\n",
    "        final_json[artist]['Concerts'] = {}\n",
    "\n",
    "    if artist in information:\n",
    "        final_json[artist]['Concerts'] = information[artist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spotify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Spotify:</b> we use the <i>Spotipy</i> library to obtain the most listened songs of each of the artists with upcoming concerts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <i>Spotipy</i> general functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPOTIPY AUTHORIZATION\n",
    "SCOPE = 'user-top-read user-read-currently-playing user-modify-playback-state'\n",
    "CACHE = '.spotipyoauthcache'\n",
    "\n",
    "try:\n",
    "    sp_oauth = oauth2.SpotifyOAuth( SPOTIPY_CLIENT_ID, SPOTIPY_CLIENT_SECRET,SPOTIPY_REDIRECT_URI, scope=SCOPE,cache_path=CACHE )\n",
    "except:\n",
    "    raise('not completed')\n",
    "\n",
    "spotify = spotipy.Spotify(client_credentials_manager=SpotifyClientCredentials(SPOTIPY_CLIENT_ID, SPOTIPY_CLIENT_SECRET))\n",
    "\n",
    "# Functions\n",
    "# --- Search artists\n",
    "def search_artist(name: str):\n",
    "    results = spotify.search(q='artist:' + name, type='artist')\n",
    "    items = results['artists']['items']\n",
    "    if len(items) > 0:\n",
    "        artist = items[0]\n",
    "    return artist.get('uri', None)\n",
    "\n",
    "# --- Track info about each artist\n",
    "def track_info(artist: str):\n",
    "    if not isinstance(artist, str):\n",
    "        raise ValueError(\"El argumento 'artist' debe ser una cadena (string)\")\n",
    "    results = spotify.artist_top_tracks(search_artist(artist))\n",
    "    res = {}\n",
    "    for track in (results['tracks'][:5]):\n",
    "        res[str(track['name'])] = {\n",
    "            'name':  track['name'],\n",
    "            'popularity': track['popularity'],\n",
    "            'url': track['uri'],\n",
    "            'album_type': track['album']['album_type'],\n",
    "            'album_name': track['album']['name']\n",
    "        }\n",
    "    return dict(res)\n",
    "\n",
    "# --- Json storage of the data\n",
    "def final_json_store(total: dict):\n",
    "    for artist in total:\n",
    "        # Track info about an artist\n",
    "        most_listened_songs = track_info(artist)\n",
    "\n",
    "        # Check if 'Spotify tracks' key exists, if not, create it\n",
    "        if 'Spotify tracks' not in total[artist]:\n",
    "            total[artist]['Spotify tracks'] = {}\n",
    "\n",
    "        # Add the most listened songs\n",
    "        total[artist]['Spotify tracks'] = most_listened_songs\n",
    "    return total  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storage of the spotify songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_added = final_json_store(final_json)\n",
    "final_json.update(spotify_added)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Setlist:</b> we use the <i>Setlist API</i> to obtain the most played songs in the past concerts of each artist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <i>Setlist</i> general functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to obtain setlist information from a given artist\n",
    "def get_setlist_data(arid: str, option: str):    \n",
    "    check_limit()\n",
    "    # Heaaders for the GET request\n",
    "    headers = {\n",
    "    'Accept': 'application/json',\n",
    "    'x-api-key': SETLIST_API_KEY,\n",
    "    }\n",
    "    # Append the artist id for the search\n",
    "    url_setlist = \"https://api.setlist.fm/rest/1.0/search/setlists?artistMbid=\"+str(arid)+\"&p=1\"\n",
    "    response = requests.get(url_setlist, headers=headers)\n",
    "    # Transform the response into json\n",
    "    data = response.json()\n",
    "\n",
    "    empty = True\n",
    "    i=0\n",
    "    recents = []\n",
    "    max = 9 # Number of setlists to gather data from\n",
    "    # Loop to find the latest non empty setlist\n",
    "    while empty == True:\n",
    "        # Current setlist\n",
    "        try:\n",
    "            setlist = data['setlist'][i]['sets']['set']\n",
    "        except IndexError:\n",
    "            return recents\n",
    "        except KeyError:\n",
    "            return recents\n",
    "        # Check if empty\n",
    "        if len(setlist) == 0:\n",
    "            i += 1\n",
    "        else:\n",
    "            # Return last setlist\n",
    "            if option == \"latest\":\n",
    "                empty = False\n",
    "                return data['setlist'][i]\n",
    "            # Return 8 last setlists\n",
    "            if option == \"8_most_recent\":\n",
    "                i += 1\n",
    "                max -= 1\n",
    "                if max == 0:\n",
    "                    empty = False\n",
    "                else:\n",
    "                    try:\n",
    "                        recents.append(data['setlist'][i])\n",
    "                    except IndexError:\n",
    "                        return recents\n",
    "    # Return setlist data, including venue, name, songs played...\n",
    "    return recents\n",
    "\n",
    "# Function that returns a dict containing every song played in a given concert\n",
    "def get_songs(setlist_data):\n",
    "    # Song dictionary for the result and counter of songs and sets\n",
    "    song_dict = {}\n",
    "    i = 1\n",
    "    set_n = 1\n",
    "\n",
    "    # Loop through every set in the concert\n",
    "    for set in setlist_data['sets']['set']:\n",
    "        set_n += 1\n",
    "        # Check if the set is empty\n",
    "        if len(set) != 0:\n",
    "            # Loop through every song and update the result dictionary\n",
    "            for song in set['song']:\n",
    "                song_dict.update({str(i): song['name']})\n",
    "                i+= 1\n",
    "    return song_dict\n",
    "    \n",
    "# Function to return the musicbrainzId of a given artist for use in other functions\n",
    "def get_mb_id(artist:str):\n",
    "    check_limit()\n",
    "    # Get request given an input artist name\n",
    "    url = \"http://musicbrainz.org/ws/2/artist/?query=artist:\"+str(artist)\n",
    "    \n",
    "    response = requests.get(url, headers={\"Accept\": \"application/json\"})\n",
    "    # Make sure the response is in utf-8 to avoid formatting issues\n",
    "    response.encoding = 'utf-8'\n",
    "    # Transform the response into json\n",
    "    data = response.json()\n",
    "    # Locate the artist MBid and return it\n",
    "    id = data['artists'][0]['id']\n",
    "    return id\n",
    "\n",
    "# Given the name of an artist, return top 5 played songs in its last 8 concerts\n",
    "def get_5_most_played(artist):\n",
    "    top_songs = {}\n",
    "    # Obtain the mbId of an artist to retrieve its data\n",
    "    arid = get_mb_id(artist)\n",
    "    # Obtain the 8 latest concerts of said artist\n",
    "    last_8_setlist = get_setlist_data(arid, \"8_most_recent\")\n",
    "    # Append all songs played in a concert to a list\n",
    "    all_songs = get_8_songlist(last_8_setlist)\n",
    "    # Create a dict with key: song and value: times played over the last 8 concerts\n",
    "    for song in all_songs:\n",
    "        if song in top_songs:\n",
    "            top_songs[song] += 1\n",
    "        else:\n",
    "            top_songs[song] = 1\n",
    "    # Sort the dictionary in descending order\n",
    "    sorted_top = sorted(top_songs.items(), key=lambda x: x[1], reverse=True)\n",
    "    index = 0\n",
    "    top5 = {}\n",
    "    # Get the top 5 songs from the dict\n",
    "    while index < 5:\n",
    "        try:\n",
    "            top5.update({sorted_top[index][0]:sorted_top[index][1]})\n",
    "        except IndexError:\n",
    "            break\n",
    "        index += 1\n",
    "    return top5\n",
    "\n",
    "# Given 8 setlists, return all songs played\n",
    "def get_8_songlist(last_8_setlist):\n",
    "    all_songs = []\n",
    "    # Loop through each setlist\n",
    "    for setlist in last_8_setlist:\n",
    "        songs_played = get_songs(setlist)\n",
    "        # Append each song\n",
    "        for song in songs_played.values():\n",
    "            all_songs.append(song)\n",
    "    return all_songs\n",
    "\n",
    "def venue_set(venue: str, artist_name: str):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 5 most played songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "topSongs_dict = {}\n",
    "\n",
    "# Get the top 5 songs of a group of artists and dump it in a JSON file\n",
    "top_songs_dict = {}\n",
    "for artist in TOP_ARTISTS:\n",
    "    clear_output(wait=True)  # Clear output so messages don't pile up\n",
    "    top_songs_dict[artist] = get_5_most_played(artist)\n",
    "clear_output(wait=True)\n",
    "\n",
    "for artist in final_json:\n",
    "    try:\n",
    "        final_json[artist]['Setlist tracks'] = top_songs_dict[artist]\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setlist ft. Spotify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Setlist ft Spotify</b>: we join these two data sections in order to have the most probable songs the artist will play (the most played <b>and</b> most listened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the coincidences between most listened songs and most played in concerts from each artist\n",
    "\n",
    "# Functions\n",
    "# --- Check if any of the dictionaries is empty\n",
    "def is_empty(setlist_dict: dict, spotify_dict: dict):\n",
    "    if setlist_dict == {} or spotify_dict == {}:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# --- Compare the keys of two dictionaries in order to find common keys\n",
    "def compare_keys(nested_dict1: dict, nested_dict2: dict):\n",
    "    common_keys = []\n",
    "    for keys1 in nested_dict1:\n",
    "        for keys2 in nested_dict2:\n",
    "            if keys1 == keys2:\n",
    "                common_keys.append(keys1)\n",
    "    return common_keys\n",
    "\n",
    "# --- Compare the songs of each artists and find the coincidences\n",
    "def top5_compare(setlist_dict, spotify_dict):\n",
    "    if is_empty(setlist_dict, spotify_dict):\n",
    "        return {}\n",
    "    common_artists = compare_keys(setlist_dict, spotify_dict)\n",
    "    common_songs = {}\n",
    "    for artist in common_artists:\n",
    "        common_songs[artist] = compare_keys(setlist_dict[artist], spotify_dict[artist])\n",
    "    return common_songs\n",
    "\n",
    "# --- Create a new dictionary with the data we want\n",
    "def set_new_list(artist, songs: set, setlist_dict: dict, spotify_dict: dict):\n",
    "    song_dict = {}\n",
    "    for song in songs:\n",
    "        if song in spotify_dict.get(artist, {}) and song in setlist_dict.get(artist, {}):\n",
    "            song_dict[song] = {\n",
    "                'name': spotify_dict[artist][song]['name'],\n",
    "                'times it has been played': setlist_dict[artist][song],\n",
    "                'album': spotify_dict[artist][song]['name']\n",
    "            }\n",
    "    return song_dict\n",
    "\n",
    "\n",
    "setlist_dict = {}\n",
    "spotify_dict = {}\n",
    "# CODE: obtain the data and store it after comparison\n",
    "\n",
    "for artist in final_json:\n",
    "    # Top 5 most played songs from each artist\n",
    "    if 'Setlist tracks' in final_json[artist]:\n",
    "        setlist_dict[artist] = final_json[artist]['Setlist tracks']\n",
    "\n",
    "    # Top 5 most listened songs from each artist\n",
    "    if 'Spotify tracks' in final_json[artist]:\n",
    "        spotify_dict[artist] = final_json[artist]['Spotify tracks']\n",
    "\n",
    "\n",
    "# Create the comparison betweeen both files\n",
    "common_songs = top5_compare(setlist_dict, spotify_dict)\n",
    "final_dict = {}\n",
    "for artist in common_songs:\n",
    "        final_dict[artist] = set_new_list(artist, common_songs[artist], setlist_dict, spotify_dict)\n",
    "\n",
    "# We store the information in the final json file\n",
    "for artist in final_json:\n",
    "    if 'Spotify and Setlist' not in final_json[artist]:\n",
    "        final_json[artist]['Spotify and Setlist'] = {}\n",
    "\n",
    "    if artist in final_dict:\n",
    "        final_json[artist]['Spotify and Setlist'] = final_dict[artist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lyric scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BeautifulSoup:** Using BeautifulSoup we scrape the lyrics of the songs we have gathered. The lyrics come from Genius. We use SpaCy to process the lyrics and then store the word count of each song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding the lyric analysis for: Arctic Monkeys - R U Mine?\n"
     ]
    }
   ],
   "source": [
    "## Scrapes lyrics from Genius and counts the number of lemmatized words in each song.\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "\n",
    "import spacy\n",
    "from langdetect import detect\n",
    "import unicodedata\n",
    "\n",
    "if not spacy.util.is_package('en_core_web_sm'):\n",
    "    spacy.cli.download('en_core_web_sm')\n",
    "if not spacy.util.is_package('es_core_news_sm'):\n",
    "    spacy.cli.download('es_core_news_sm')\n",
    "\n",
    "nlp_en = spacy.load('en_core_web_sm')\n",
    "nlp_es = spacy.load('es_core_news_sm')\n",
    "\n",
    "stopwords_en = nlp_en.Defaults.stop_words\n",
    "stopwords_es = nlp_es.Defaults.stop_words\n",
    "\n",
    "def get_link(artist: str, song: str) -> str:\n",
    "    \"\"\"\n",
    "    Gets the link to the lyrics page on Genius.\n",
    "    Args:\n",
    "        artist (str): Artist name\n",
    "        song (str): Song name\n",
    "    \"\"\"\n",
    "    artist = artist.replace(' ', '-')\n",
    "    song = remove_punctuation_contractions(song).replace(' ', '-')\n",
    "\n",
    "    return f'https://www.genius.com/{artist}-{song}-lyrics'\n",
    "\n",
    "def get_lyrics(artist: str, song: str) -> str or None:\n",
    "    \"\"\"\n",
    "    Gets the lyrics from Genius.\n",
    "    Returns None if the lyrics page does not exist.\n",
    "    Args:\n",
    "        artist (str): Artist name\n",
    "        song (str): Song name\n",
    "    \"\"\"\n",
    "    link = get_link(artist, song)\n",
    "    page = requests.get(link)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    try:\n",
    "        lyrics = soup.find('div', class_='Lyrics__Container-sc-1ynbvzw-1 kUgSbL').get_text(separator=\" \")\n",
    "    except AttributeError:\n",
    "        return None\n",
    "    lyrics = re.sub(r'\\[.*?\\]', '', lyrics)  # remove tags between brackets\n",
    "    lyrics = re.sub(r'\\s+', ' ', lyrics)  # replace consecutive whitespace with a single space\n",
    "    return lyrics.strip()\n",
    "\n",
    "def remove_stopwords(lyrics: str) -> str:\n",
    "    \"\"\"\n",
    "    Removes stopwords from the lyrics.\n",
    "    Args:\n",
    "        lyrics (str): Lyrics\n",
    "    \"\"\"\n",
    "    if not lyrics:\n",
    "        return ''\n",
    "    stopwords = stopwords_es if detect(lyrics) == 'spanish' else stopwords_en\n",
    "    return ' '.join([word for word in lyrics.split() if word not in stopwords])\n",
    "\n",
    "def remove_punctuation_contractions(lyrics: str) -> str:\n",
    "    \"\"\"\n",
    "    Removes punctuation and contractions from the lyrics.\n",
    "    Args:\n",
    "        lyrics (str): Lyrics\n",
    "    \"\"\"\n",
    "    lyrics = ''.join(c for c in unicodedata.normalize('NFD', lyrics) if unicodedata.category(c) != 'Mn')  # remove diacritics\n",
    "    lyrics = re.sub(r'[^\\w\\s]', '', lyrics)  # remove punctuation\n",
    "    lyrics = re.sub(r\"(\\b\\w+)'(\\w+\\b)\", r'\\1\\2', lyrics)  # remove contractions\n",
    "    return lyrics\n",
    "\n",
    "def preprocess(lyrics: str) -> str:\n",
    "    \"\"\"\n",
    "    Preprocesses the lyrics.\n",
    "    Args:\n",
    "        lyrics (str): Lyrics\n",
    "    \"\"\"\n",
    "    return remove_punctuation_contractions(remove_stopwords(lyrics))\n",
    "\n",
    "def count_lemmatized_words(lyrics):\n",
    "    \"\"\"\n",
    "    Counts the number of lemmatized words in the lyrics.\n",
    "    Args:\n",
    "        lyrics (str): Lyrics\n",
    "    \"\"\"\n",
    "    if not lyrics:\n",
    "        return {}\n",
    "    \n",
    "    if detect(lyrics) == 'spanish':\n",
    "        stopwords = stopwords_es\n",
    "        doc = nlp_es(lyrics)\n",
    "    else:\n",
    "        stopwords = stopwords_en\n",
    "        doc = nlp_en(lyrics)\n",
    "    \n",
    "    word_count = defaultdict(int)  # default value for the count of a word is 0\n",
    "\n",
    "    for token in doc:\n",
    "        lemma = token.lemma_.lower()  # Converting to lowercase for consistent results\n",
    "        if lemma not in stopwords and len(lemma) > 2:\n",
    "            word_count[lemma] += 1\n",
    "\n",
    "    return word_count\n",
    "\n",
    "def write_json(data: dict, filename: str):\n",
    "    \"\"\"\n",
    "    Writes the data to a JSON file. (Unused utility function.)\n",
    "    Args:\n",
    "        data (dict): Dictionary to write\n",
    "        filename (str): Name of the file\n",
    "    \"\"\"\n",
    "    import json\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "def get_songs() -> list:\n",
    "    \"\"\"\n",
    "    Reads final_json and returns a list of tuples of the form (Artist, Title).\n",
    "    \"\"\"\n",
    "    songs = []\n",
    "    for artist in final_json:\n",
    "        for title in final_json[artist][\"Spotify tracks\"]:\n",
    "            print(f\"Analyzing the lyrics for: {artist} - {title}\")\n",
    "            songs.append((artist, title))\n",
    "        clear_output(wait=True)\n",
    "    return songs\n",
    "\n",
    "songs = get_songs()\n",
    "for artist, title in songs:\n",
    "    print(f\"Adding the lyric analysis for: {artist} - {title}\")\n",
    "    words = count_lemmatized_words(preprocess(get_lyrics(artist, title)))\n",
    "    final_json[artist][\"Spotify tracks\"][title][\"words\"] = words\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Data storage:</b> we store the data back to our json file, once it has been updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('data.json', 'w') as file:\n",
    "        json.dump(final_json, file, indent=4)\n",
    "except TypeError as e:\n",
    "    raise Exception(f'Error: {e}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
